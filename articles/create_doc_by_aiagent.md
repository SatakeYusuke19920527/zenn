---
title: 'AI Agent ã«AIæœ€æ–°æƒ…å ±ã¾ã¨ã‚è³‡æ–™ã‚’ä½œã£ã¦ã‚‚ã‚‰ã†ä¼šã€LangGraph/LangSmithã€‘'
emoji: 'ğŸ“'
type: 'tech' # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ['AI', 'LangGraph', 'LangSmith', 'AzureOpenAI', 'AIAgent']
published: false
publication_name: microsoft
---

# ã¯ã˜ã‚ã«

https://youtu.be/dBI7LhHfto0

ä»Šå›ã¯ AI Agent ã« AI é–¢é€£ã®æœ€æ–°æƒ…å ±ã‚’å–å¾—ã—ã€ã‚¹ãƒ©ã‚¤ãƒ‰å½¢å¼ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¾ã¨ã‚ã¦ã‚‚ã‚‰ã† PoC ã‚’ä½œæˆã—ã¦ã¿ã¾ã—ãŸã€‚
å®Ÿè£…ã¯ Python ã®ã¿ã§ã€LangChainãƒ»LangGraphãƒ»LangSmith ã‚’æ´»ç”¨ã—ç°¡å˜ã«å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚

å…¨ä½“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ•ãƒ­ãƒ¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ„Ÿã˜ã§ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/22e4ae811c7b-20250906.png)

ãƒ•ãƒ­ãƒ¼ã‚’ã–ã£ãã‚Šèª¬æ˜ã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

0. collect_info -> Tavily æƒ…å ±åé›†
1. make_outline -> ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆ
2. make_toc -> ç›®æ¬¡ç”Ÿæˆï¼ˆJSONï¼‰
3. write_slides -> ã‚¹ãƒ©ã‚¤ãƒ‰æœ¬æ–‡ç”Ÿæˆï¼ˆMarpï¼‰
4. evaluate_slides -> è‡ªå‹•è©•ä¾¡ã¨ãƒªãƒˆãƒ©ã‚¤åˆ†å²
5. save_and_render -> ä¿å­˜ & marp-cli ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°

LangGraph ã§ AI Agent ã‚’å®Ÿè£…ã—ã¤ã¤ã€LangSmith ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ãã®å¯è¦–åŒ–ã‚’è¡Œã„ãªãŒã‚‰ AI Agent ã®å‹•ãã‚’å­¦ã¹ã‚‹å†…å®¹ã«ãªã‚Šã¾ã™ã€‚

# ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®èª¬æ˜

## LangChain ã¨ã¯

![](https://storage.googleapis.com/zenn-user-upload/7f13d4a0fd14-20250906.png)

**LangChain** ã¯ã€**å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«çµ„ã¿è¾¼ã‚€ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**ã§ã€LLM ã‚’å˜ãªã‚‹æ–‡ç« ç”Ÿæˆã«ã¨ã©ã‚ãšã€å¤–éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„ APIã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã¤ãªã’ã¦ã€ **å®Ÿéš›ã«å½¹ç«‹ã¤ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆAI Agent ã‚„ RAG ã‚·ã‚¹ãƒ†ãƒ ï¼‰**ã‚’ä½œã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚

- **é–‹ç™ºå…ƒ**: ç±³å›½ã® LangChain, Inc.
- **åˆ©ç”¨åˆ†é‡**: AI ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã‹ã‚‰å¤§ä¼æ¥­ã¾ã§å¹…åºƒãæ¡ç”¨
- **ç‰¹å¾´**: ãƒ¢ãƒ‡ãƒ«æ¥ç¶šã€ãƒ„ãƒ¼ãƒ«çµ±åˆã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰ã€è©•ä¾¡åŸºç›¤ã¾ã§ä¸€æ°—é€šè²«ã§ã‚«ãƒãƒ¼

### ä¸»ãªæ©Ÿèƒ½

#### 1. LLM ãƒ©ãƒƒãƒ‘ãƒ¼

- OpenAI, Azure OpenAI, Anthropic, Google Gemini ãªã©å¤šæ•°ã®ãƒ¢ãƒ‡ãƒ«ã«å…±é€š API ã§æ¥ç¶šã€‚

#### 2. Tools

- æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã€DB ã‚¯ã‚¨ãƒªã€Python å®Ÿè¡Œç’°å¢ƒãªã©ã‚’ã€Œãƒ„ãƒ¼ãƒ«ã€ã¨ã—ã¦å‘¼ã³å‡ºã—å¯èƒ½ã€‚

#### 3. Agents

- LLM ãŒã‚¿ã‚¹ã‚¯ã‚’ç†è§£ã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ„ãƒ¼ãƒ«ã‚’åˆ©ç”¨ã—ã¦**è‡ªå¾‹çš„ã«å‡¦ç†**ã€‚
- ä¾‹: ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå• â†’ Web æ¤œç´¢ â†’ è¦ç´„ â†’ å›ç­”ç”Ÿæˆã€

#### 4. Chains

- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€LLMã€ãƒ„ãƒ¼ãƒ«ã€å‡ºåŠ›å‡¦ç†ã‚’çµ„ã¿åˆã‚ã›ãŸ**å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã€‚

#### 5. Memory

- ä¼šè©±å±¥æ­´ã‚„çŠ¶æ…‹ã‚’ä¿æŒã—ã¦ã€**æ–‡è„ˆã‚’ç†è§£ã—ãŸç¶™ç¶šçš„ãªå¯¾è©±**ã‚’å®Ÿç¾ã€‚

### LangChain ã§ä½œã‚Œã‚‹ã‚‚ã®ã®ä¾‹

- **RAGï¼ˆæ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼‰ã‚·ã‚¹ãƒ†ãƒ **  
  â†’ ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢ã—ã¦æ­£ç¢ºãªå›ç­”ã‚’è¿”ã™ QA ã‚¢ãƒ—ãƒª

- **AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**  
  â†’ ã‚¿ã‚¹ã‚¯ã‚’ç†è§£ã—ã€API å‘¼ã³å‡ºã—ã‚„è³‡æ–™è‡ªå‹•ç”Ÿæˆã‚’è¡Œã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ

- **ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ **  
  â†’ å½¹å‰²åˆ†æ‹…ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ãŒå”èª¿ã—ã¦å•é¡Œè§£æ±º

- **æ¥­å‹™è‡ªå‹•åŒ– Bot**  
  â†’ ãƒ¡ãƒ¼ãƒ«ä¸‹æ›¸ãã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã€é¡§å®¢å¯¾å¿œãªã©ã‚’åŠè‡ªå‹•åŒ–

LangChain ã¯ã€ŒLLM ã‚’ä½¿ã†ã€ã‹ã‚‰ã€ŒLLM ã§ã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ã€ã¸é€²åŒ–ã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚  
ç‰¹ã« **AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ** ã‚„ **RAG ã‚·ã‚¹ãƒ†ãƒ ** ã®å®Ÿè£…åŸºç›¤ã¨ã—ã¦ä¸–ç•Œä¸­ã§æ³¨ç›®ã‚’é›†ã‚ã¦ã„ã¾ã™ã€‚

## LangGraph ã¨ã¯

![](https://storage.googleapis.com/zenn-user-upload/22e4ae811c7b-20250906.png)

**LangGraph** ã¯ã€**LangChain ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸçŠ¶æ…‹é·ç§»å‹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**ã§ã™ã€‚  
AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚„è¤‡é›‘ãªå¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã‚’ã€Œã‚°ãƒ©ãƒ•ï¼ˆãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ï¼‰ã€ã¨ã—ã¦è¨­è¨ˆã§ãã‚‹ã®ãŒç‰¹å¾´ã§ã™ã€‚

## ä¸»ãªç‰¹å¾´

### 1. çŠ¶æ…‹é·ç§»å‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

- å„å‡¦ç†ï¼ˆãƒãƒ¼ãƒ‰ï¼‰ã‚’æ˜ç¤ºçš„ã«å®šç¾©ã—ã€å‡¦ç†ã®æµã‚Œï¼ˆã‚¨ãƒƒã‚¸ï¼‰ã‚’ã¤ãªã’ã‚‹ã€‚
- `StateGraph` ã‚’ä½¿ã£ã¦ã€é–‹å§‹ï¼ˆSTARTï¼‰ã‹ã‚‰çµ‚äº†ï¼ˆENDï¼‰ã¾ã§ã®æµã‚Œã‚’åˆ¶å¾¡ã€‚

### 2. ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã®åˆ¶å¾¡

- å˜ç´”ãª LLM å‘¼ã³å‡ºã—ã ã‘ã§ãªãã€**æ¡ä»¶åˆ†å²**ã‚„**ãƒ«ãƒ¼ãƒ—**ã‚’å®Ÿè£…å¯èƒ½ã€‚
- ã€Œå¤±æ•—ã—ãŸã‚‰ãƒªãƒˆãƒ©ã‚¤ã€ã€Œè©•ä¾¡ã‚¹ã‚³ã‚¢ãŒä½ã‘ã‚Œã°åˆ¥ãƒ«ãƒ¼ãƒˆã¸ã€ãªã©ã‚’è¨­è¨ˆã§ãã‚‹ã€‚

### 3. LangChain ã¨ã®è¦ªå’Œæ€§

- LangChain ã®**ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**ã‚„**ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—**ã‚’ãã®ã¾ã¾çµ„ã¿è¾¼ã¿å¯èƒ½ã€‚
- LLM ï¼‹å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ï¼‹ RAG ã®æµã‚Œã‚’**ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–**ã§ãã‚‹ã€‚

## å…¸å‹çš„ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹

- **AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**
  - è¤‡æ•°ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµŒã¦ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã€‚
- **ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ **
  - å½¹å‰²ã”ã¨ã«ç•°ãªã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é…ç½®ã—ã€å”èª¿ã•ã›ã‚‹ã€‚
- **RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**
  - æ¤œç´¢ â†’ è©•ä¾¡ â†’ å›ç­”ç”Ÿæˆ ã®æµã‚Œã‚’ã‚°ãƒ©ãƒ•ã§è¡¨ç¾ã€‚
- **æ¡ä»¶ä»˜ãã‚¿ã‚¹ã‚¯å®Ÿè¡Œ**
  - è©•ä¾¡ã‚¹ã‚³ã‚¢ã‚„å¤–éƒ¨ã‚·ã‚°ãƒŠãƒ«ã«å¿œã˜ã¦ãƒ«ãƒ¼ãƒˆã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã€‚

å®Ÿéš›ã«ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ãŸæ–¹ãŒã‚¤ãƒ¡ãƒ¼ã‚¸ãŒã¤ãã‚„ã™ã„ã¨æ€ã†ã®ã§ã€ä»¥ä¸‹ã«ç°¡å˜ãªã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ç¤ºã—ã¾ã™ã€‚

## ç°¡å˜ãªã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰

```python
from langgraph.graph import StateGraph, START, END

# StateGraphã‚’å®šç¾©
graph = StateGraph(dict)

# ãƒãƒ¼ãƒ‰ã‚’å®šç¾©
def step1(state):
    print("Step1")
    return {"x": 1}

def step2(state):
    print("Step2")
    return {"y": state["x"] + 1}

# ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
graph.add_node("step1", step1)
graph.add_node("step2", step2)

# ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
graph.add_edge(START, "step1")
graph.add_edge("step1", "step2")
graph.add_edge("step2", END)

# å®Ÿè¡Œ
app = graph.compile()
result = app.invoke({})
print(result)
```

ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰å†…ã§å„å‡¦ç†ï¼ˆãƒãƒ¼ãƒ‰ï¼‰ã‚’æ˜ç¤ºçš„ã«å®šç¾©ã—ã¦ã€å‡¦ç†ã®æµã‚Œï¼ˆã‚¨ãƒƒã‚¸ï¼‰ã‚’ç¹‹ã’ã¦ã„ã¾ã™ã­ã€‚
ã“ã®ã‚ˆã†ã«ã€LangGraph ã¯ã€**ã€ŒAI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’çŠ¶æ…‹é·ç§»ã‚°ãƒ©ãƒ•ã§è¡¨ç¾ã™ã‚‹ä»•çµ„ã¿ã€**ã§ã™ã€‚

## LangSmith ã¨ã¯

![](https://storage.googleapis.com/zenn-user-upload/5fab28b94335-20250906.png)

**LangSmith** ã¯ã€LangChain å…¬å¼ãŒæä¾›ã™ã‚‹ **LLM ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è©•ä¾¡ãƒ»ãƒ‡ãƒãƒƒã‚°ãƒ»ç›£è¦–ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ** ã§ã™ã€‚  
AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚„ RAG ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã«ãŠã„ã¦ã€**ã€Œã©ã†å‹•ã„ãŸã‹ã€ã€Œã©ã®éƒ¨åˆ†ãŒæ‚ªã„ã‹ã€**ã‚’å¯è¦–åŒ–ã™ã‚‹ãŸã‚ã«ä½¿ã‚ã‚Œã¾ã™ã€‚

## ä¸»ãªç‰¹å¾´

### 1. ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ï¼ˆTracingï¼‰

- LLM å‘¼ã³å‡ºã—ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚’**æ™‚ç³»åˆ—ã§è¨˜éŒ²**ã€‚
- å®Ÿéš›ã®å…¥åŠ›ã¨å‡ºåŠ›ã‚’**å¯è¦–åŒ–ã—ã¦ãƒ‡ãƒãƒƒã‚°**å¯èƒ½ã€‚

### 2. è©•ä¾¡ï¼ˆEvaluationï¼‰

- **è‡ªå‹•è©•ä¾¡ï¼ˆAuto Evalï¼‰**: LLM ã‚„å®šç¾©æ¸ˆã¿åŸºæº–ã‚’ä½¿ã£ãŸå“è³ªè©•ä¾¡ã€‚
- **äººæ‰‹è©•ä¾¡ï¼ˆHuman Evalï¼‰**: ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãŒãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸ã—ã€å›ç­”ã®è‰¯ã—æ‚ªã—ã‚’ãƒã‚§ãƒƒã‚¯ã€‚
- ã‚¹ã‚³ã‚¢åŒ–ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã«ã‚ˆã‚Šæ”¹å–„ã‚’ç¶™ç¶šã€‚

### 3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†

- ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåŒ–**ã—ã¦ä¿å­˜ã€‚
- å›å¸°ãƒ†ã‚¹ãƒˆã®ã‚ˆã†ã«**åŒã˜ã‚±ãƒ¼ã‚¹ã§å†è©•ä¾¡**ã§ãã‚‹ã€‚

### 4. LangChain/LangGraph ã¨ã®çµ±åˆ

- LangChain ã‚¢ãƒ—ãƒªã§ `@traceable` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ä»˜ã‘ã‚‹ã ã‘ã§**è‡ªå‹•çš„ã« LangSmith ã«è¨˜éŒ²**ã€‚
- LangGraph ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚‚å¯è¦–åŒ–ã•ã‚Œã‚‹ã€‚

---

## ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹

- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„**  
  ã©ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä¸é©åˆ‡ã‹ã€ã©ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒå¤±æ•—ã—ãŸã‹ã‚’åˆ†æã€‚

- **RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è©•ä¾¡**  
  ã€Œæ¤œç´¢ â†’ å›ç­”ç”Ÿæˆã€ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒæ­£ã—ãå‹•ã„ã¦ã„ã‚‹ã‹ç¢ºèªã€‚

- **AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å“è³ªä¿è¨¼**  
  è¤‡é›‘ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’**ãƒˆãƒ¬ãƒ¼ã‚¹ & ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°**ã—ã¦ä¿¡é ¼æ€§ã‚’æ‹…ä¿ã€‚

---

## ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆç°¡ç•¥ï¼‰

```python
from langsmith import traceable

@traceable
def my_chain(input: str) -> str:
    # LangSmithã§ãƒˆãƒ¬ãƒ¼ã‚¹ã•ã‚Œã‚‹
    return f"Hello, {input}"

print(my_chain("Yusuke"))
```

ä¸Šè¨˜ã®ã‚ˆã†ã« @traceable ã‚’ä»˜ã‘ã‚‹ã¨ã€LangSmith ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§å…¥åŠ›ã¨å‡ºåŠ›ãŒè¿½è·¡å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚
LangChain ã‚¢ãƒ—ãƒªã‚’æœ¬ç•ªé‹ç”¨ã§ãã‚‹å“è³ªã«å¼•ãä¸Šã’ã‚‹å½¹å‰²ã‚’æ‹…ã„ã¾ã™ã€‚
Dev â†’ Test â†’ Prod ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«å…¨ä½“ã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã®ã§ã€LLM ã‚¢ãƒ—ãƒªã®å“è³ªç®¡ç†ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚

**ã¾ã¨ã‚ã‚‹ã¨ä»¥ä¸‹ã®ç†è§£ã§ OK ã§ã™ã€‚**

- LangChain = é–‹ç™ºï¼ˆã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ï¼‰
- LangGraph = è¨­è¨ˆï¼ˆãƒ•ãƒ­ãƒ¼ã‚’çµ„ã‚€ï¼‰
- LangSmith = é‹ç”¨ï¼ˆLLMOps ã§å“è³ªç®¡ç†ï¼‰

## Tavily ã¨ã¯

![](https://storage.googleapis.com/zenn-user-upload/740cc2c00d8e-20250906.png)

**Tavily** ã¯ã€**AI å‘ã‘ã®æ¤œç´¢ãƒ»æƒ…å ±åé›† API** ã‚’æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚  
å¾“æ¥ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã«æ¯”ã¹ã¦ã€**LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ãŒæ‰±ã„ã‚„ã™ã„å½¢å¼ã§æƒ…å ±ã‚’è¿”ã™**ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚

- **ç”¨é€”**: AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚„ RAGï¼ˆæ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼‰ã®ã€Œæƒ…å ±åé›†éƒ¨åˆ†ã€ã«åˆ©ç”¨
- **å¼·ã¿**: JSON å½¢å¼ã§ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€è¦ç´„ä»˜ãæ¤œç´¢çµæœã€è¤‡æ•°ã‚¯ã‚¨ãƒªå‡¦ç†ã€é®®åº¦åˆ¶å¾¡ï¼ˆç›´è¿‘ã®æƒ…å ±ã ã‘ã‚’å–å¾—ï¼‰

## ä¸»ãªç‰¹å¾´

### 1. é«˜ç²¾åº¦ãª Web æ¤œç´¢

- é€šå¸¸ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã«æ¯”ã¹ã€ãƒã‚¤ã‚ºã‚’æ¸›ã‚‰ã—**çŸ­æ–‡ã‚µãƒãƒªï¼‹ãƒªãƒ³ã‚¯ä»˜ã**ã§è¿”ã™ã€‚
- LLM ã«ç›´æ¥æ¸¡ã—ã‚„ã™ã„å½¢å¼ã§æƒ…å ±ã‚’æä¾›ã€‚

### 2. æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆJSONï¼‰

- ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã¯ã€Œtitleã€ã€Œurlã€ã€Œcontentï¼ˆã‚µãƒãƒªï¼‰ã€ãŒå«ã¾ã‚Œã‚‹ã€‚
- ãã®ã¾ã¾ LangChain ãªã©ã®ãƒ„ãƒ¼ãƒ«ã«çµ„ã¿è¾¼ã‚ã‚‹ã€‚

### 3. ã‚¯ã‚¨ãƒªåˆ¶å¾¡

- `time_range` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€Œday / week / month / yearã€ãªã©ã€**æƒ…å ±ã®é®®åº¦ã‚’æŒ‡å®šå¯èƒ½**ã€‚
- å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆä¾‹: microsoft.com, openai.comï¼‰ã®ã¿ã«é™å®šã—ã¦æ¤œç´¢ã§ãã‚‹ã€‚

### 4. AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®ç›¸æ€§

- **LangChain / LangGraph** ã®ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ä½¿ã„ã‚„ã™ã„ã€‚
- æœ€æ–°æƒ…å ±ã‚’å–ã‚Šè¾¼ã¿ãªãŒã‚‰ã€RAG ã‚„ã‚¹ãƒ©ã‚¤ãƒ‰è‡ªå‹•ç”Ÿæˆã«æ´»ç”¨å¯èƒ½ã€‚

ä»¥ä¸‹ã« Azure ã® 2025 å¹´ã«å‡ºãŸæœ€æ–°æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ç¤ºã—ã¾ã™ã€‚

## ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆPythonï¼‰

```python
import requests

endpoint = "https://api.tavily.com/search"
payload = {
    "api_key": "YOUR_TAVILY_API_KEY",
    "query": "Azure OpenAI September 2025 updates",
    "search_depth": "advanced",
    "include_answer": True,
    "max_results": 5,
    "time_range": "month"
}

res = requests.post(endpoint, json=payload, timeout=60)
print(res.json())
```

ã™ã”ãç°¡å˜ã« WEB æ¤œç´¢ãŒå–å¾—å‡ºæ¥ã‚‹ã®ã§ã€AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æƒ…å ±åé›†ã«æœ€é©ã§ã™ã€‚

ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã¨ã—ã¦ã¯ä»¥ä¸‹ã«ãªã‚‹ã‹ã¨æ€ã„ã¾ã™ã€‚

- AI ã‚¹ãƒ©ã‚¤ãƒ‰è‡ªå‹•ç”Ÿæˆ
  - æœ€æ–°æƒ…å ±ã‚’é›†ã‚ã¦è¦ç´„ â†’ LLM ã§ã‚¹ãƒ©ã‚¤ãƒ‰åŒ–
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µãƒãƒªãƒœãƒƒãƒˆ
  - ç›´è¿‘ã®å‡ºæ¥äº‹ã ã‘ã‚’ã¾ã¨ã‚ã¦é…ä¿¡
- RAG ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–
  - ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã ã‘ã§ãªãã€Œæœ€æ–°ã® Web æƒ…å ±ã€ã‚‚å›ç­”ã«çµ±åˆ

Tavily ã¯ã€**AI ãŒå¤–éƒ¨ã®æœ€æ–°æƒ…å ±ã‚’å–ã‚Šè¾¼ã‚€ãŸã‚ã®ã€Œæ¤œç´¢ APIã€**ã§ã™ã€‚
LangChain ã‚„ LangGraph ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€æœ€æ–°æƒ…å ±ã‚’æ‰±ãˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç°¡å˜ã«æ§‹ç¯‰ã§ãã¾ã™ã€‚
ä»Šå›ã®å®Ÿè£…ã§ã¯ã€AI é–¢é€£ã®æœ€æ–°æƒ…å ±ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«æ´»ç”¨ã—ã¦ã„ã¾ã™ã€‚

## Marp ã¨ã¯

**Marp (Markdown Presentation Ecosystem)** ã¯ã€**Markdown ã§ã‚¹ãƒ©ã‚¤ãƒ‰è³‡æ–™ã‚’ä½œæˆã§ãã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯** ã§ã™ã€‚

ä»¥ä¸‹ã®ã‚ˆã†ãªåˆ©ç”¨ç”¨é€”ã«ãªã‚Šã¾ã™ã€‚

- **Markdown è¨˜æ³•ã§ãƒ—ãƒ¬ã‚¼ãƒ³è³‡æ–™ã‚’ä½œæˆå¯èƒ½**
- **ãƒ†ãƒ¼ãƒã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ã‚¹ãƒ©ã‚¤ãƒ‰åŒ–**
- **PDF / PNG / HTML å½¢å¼ã§å‡ºåŠ›å¯èƒ½**

## ä¸»ãªç‰¹å¾´

### 1. Markdown ãƒ™ãƒ¼ã‚¹

- `# ã‚¿ã‚¤ãƒˆãƒ«` â†’ ã‚¹ãƒ©ã‚¤ãƒ‰ã®è¦‹å‡ºã—
- `---` â†’ ã‚¹ãƒ©ã‚¤ãƒ‰åŒºåˆ‡ã‚Š
- æ™®æ®µã® Markdown ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°æ„Ÿè¦šã§ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½œæˆã§ãã‚‹ã€‚

### 2. å¤šæ§˜ãªå‡ºåŠ›å½¢å¼

- **PDF**: å°åˆ·ã‚„é…å¸ƒã«ä¾¿åˆ©
- **PNG**: ç”»åƒã¨ã—ã¦åˆ©ç”¨å¯èƒ½
- **HTML**: Web ä¸Šã«å…¬é–‹ãƒ»å…±æœ‰ã§ãã‚‹

### 3. ãƒ†ãƒ¼ãƒã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

- `default` / `gaia` / `uncover` ãªã©å…¬å¼ãƒ†ãƒ¼ãƒã‚’é¸æŠå¯èƒ½
- CSS ã‚„ç‹¬è‡ªãƒ†ãƒ¼ãƒã‚’ä½œæˆã—ã¦ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ‡ã‚¶ã‚¤ãƒ³ã«ã‚‚å¯¾å¿œ

### 4. CLI ãƒ„ãƒ¼ãƒ«

- `marp-cli` ã‚’ä½¿ã†ã¨ Markdown ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¯ãƒ³ã‚³ãƒãƒ³ãƒ‰ã§ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆå¯èƒ½

```bash
npx @marp-team/marp-cli slides.md --pdf
```

Marp ã¯æœ€è¿‘ç§ãŒæ„›ç”¨ã—ã¦ã„ã‚‹ã®ã§ã™ãŒã€ã‚µã‚¯ãƒƒã¨ã‚¹ãƒ©ã‚¤ãƒ‰è³‡æ–™ã‚’ä½œæˆã§ãã‚‹ã®ã§éå¸¸ã«ä¾¿åˆ©ã§ã™ã€‚
ä»Šå›ã¯ AI æœ€æ–°æƒ…å ±ã®å–å¾—å¾Œã®ã‚¹ãƒ©ã‚¤ãƒ‰åŒ–ã«æ´»ç”¨ã—ã¦ã„ã¾ã™ã€‚

# å®Ÿè£…é–‹å§‹ ğŸš€

## å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«

ä»»æ„ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ã€ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã—ã¾ã™ã€‚

- requirements.txt
- .env
- langgraph.json
- marp_agent.py
- slides/ <- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã€‚ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã« pdf ãŒå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚

ãã‚Œãã‚Œå®Ÿè£…ã—ã¦ã„ãã¾ã™ã€‚

#### requirements.txt

requirements.txt ã«ã¯ä»¥ä¸‹ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚

```plaintext
# --- Core runtime ---
requests>=2.31.0
python-dotenv>=1.0.0

# --- LangChain / LangGraph stack ---
langchain-core>=0.3.0,<0.4.0
langchain-openai>=0.2.0,<0.3.0
langgraph>=0.2.0,<0.4.0
langsmith>=0.1.0,<0.2.0

# --- Compatibility helpers ---
typing_extensions>=4.8.0
backports.zoneinfo; python_version<"3.9"

```

#### .env

.env ã«ã¯ä»¥ä¸‹ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚

```plaintext
# LangSmith
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=lsv2_pt_xxxxxxxxxxxxxxxxxxxxxxx_xxxxxxxxxx
LANGCHAIN_PROJECT=marp_agent
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://xxxxxxxxxxxxxxxx.azure.com/
AZURE_OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AZURE_OPENAI_API_VERSION=2024-12-01-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4o

# Tavily
TAVILY_API_KEY=tvly-dev-xxxxxxxxxxxxxxxxxxxxxxx

# Marp
SLIDE_FORMAT=pdf
```

LANGCHAIN_API_KEY ã¯ LangSmith ã® API ã‚­ãƒ¼ã‚’æŒ‡å®šã—ã¾ã™ã€‚
LangSmith ã‚’èµ·å‹•ã—ã¦ã€[Settings] - [API Keys] ã‹ã‚‰å–å¾—ã§ãã¾ã™ã€‚
![](https://storage.googleapis.com/zenn-user-upload/1c0ae962dd21-20250906.png)

Tavily_API_KEY ã¯ Tavily ã® API ã‚­ãƒ¼ã‚’æŒ‡å®šã—ã¾ã™ã€‚
Tavily ã«ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦ã€Top Page ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚
![](https://storage.googleapis.com/zenn-user-upload/0e21552e5066-20250906.png)

Azure OpenAI Service ã®å„ç¨® Key ã¯ Azure AI Foundry ã‚ˆã‚Šè¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚

#### langgraph.json

LangSmith ã‚’å®Ÿè¡Œã™ã‚‹ç‚ºã«æº–å‚™å¿…è¦ãªãƒ‘ãƒ¼ãƒ„ã«ãªã‚Šã¾ã™ã€‚

```json
{
  "dependencies": ["langgraph==0.5.2"],
  "graphs": {
    "poc-aiagent": {
      "path": "./marp_agent.py:graph",
      "description": "AI Agent create pdf about AI News"
    }
  },
  "env": ".env"
}
```

#### marp_agent.py

ã§ã¯ã€python ã«ã¦å®Ÿè£…ã—ã¦ã„ãã¾ã—ã‚‡ã†ã€‚

````python
# LangGraph Ã— LangSmith Ã— Azure OpenAI Ã— Tavily Ã— Marp
# ãƒ•ãƒ­ãƒ¼:
# 0) Tavilyã§æƒ…å ±åé›† -> 1) ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆ -> 2) ç›®æ¬¡ç”Ÿæˆ -> 3) ã‚¹ãƒ©ã‚¤ãƒ‰(Marp)æœ¬æ–‡ç”Ÿæˆ -> 4) è©•ä¾¡(>=8ã§OK/ãã‚Œä»¥å¤–ã¯2ã¸ãƒ«ãƒ¼ãƒ—) -> 5) ã‚¹ãƒ©ã‚¤ãƒ‰Markdownä¿å­˜(+ marp-cliã§pdf/png/htmlå‡ºåŠ›)

import os
import re
import json
import shutil
import subprocess
from typing import Any, Union
import requests  # type: ignore
from typing import TypedDict, List, Dict, Optional
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv  # type: ignore
from datetime import timedelta
from langsmith import traceable  # type: ignore
from langgraph.graph import StateGraph, START, END  # type: ignore
from langchain_openai import AzureChatOpenAI  # type: ignore
from langchain_core.runnables import RunnableConfig  # type: ignore
from zoneinfo import ZoneInfo
from langchain_core.tools import tool # type: ignore

# -------------------
# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
# -------------------
load_dotenv()

def _env(key: str, default: Optional[str] = None) -> str:
    v = os.getenv(key, default)
    if v is None:
        raise RuntimeError(f"Missing environment variable: {key}")
    return v

# LangSmithï¼ˆONæ¨å¥¨ï¼‰
os.environ.setdefault("LANGCHAIN_TRACING_V2", "true")
os.environ.setdefault("LANGCHAIN_ENDPOINT", "https://api.smith.langchain.com")

# Azure OpenAI
AZURE_OPENAI_ENDPOINT    = _env("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY     = _env("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_API_VERSION = _env("AZURE_OPENAI_API_VERSION", "2024-06-01")
AZURE_OPENAI_DEPLOYMENT  = _env("AZURE_OPENAI_DEPLOYMENT")

# Tavily
TAVILY_API_KEY = _env("TAVILY_API_KEY")

# Marp å‡ºåŠ›ï¼ˆpdf / png / htmlï¼‰ã€‚ç©ºãªã‚‰ .md ã®ã¿
SLIDE_FORMAT = os.getenv("SLIDE_FORMAT", "").lower().strip()
MARP_THEME   = os.getenv("MARP_THEME", "default")  # default, gaia, uncover ç­‰
MARP_PAGINATE = os.getenv("MARP_PAGINATE", "true") # "true"/"false"

# -------------------
# LLM ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
# -------------------
llm = AzureChatOpenAI(
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_deployment=AZURE_OPENAI_DEPLOYMENT,
    temperature=0.2,
)

# -------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -------------------
def _log(state: dict, msg: str) -> List[str]:
    return (state.get("log") or []) + [msg]

def _strip_bullets(lines: List[str]) -> List[str]:
    out = []
    for line in lines:
        t = line.strip()
        if not t:
            continue
        t = t.lstrip("ãƒ»-â€¢* \t")
        out.append(t)
    return out

def _slugify_en(text: str, max_len: int = 80) -> str:
    text = (text or "").lower()
    text = re.sub(r"[^a-z0-9]+", "-", text)
    text = re.sub(r"-+", "-", text).strip("-")
    return text[:max_len] or "slides"

def _find_json(text: str) -> Optional[str]:
    t = text.strip()
    t = re.sub(r"^```(?:json)?\s*", "", t)
    t = re.sub(r"\s*```$", "", t)
    m = re.search(r"\{.*\}\s*$", t, flags=re.DOTALL)
    if m:
        return m.group(0)
    return None

def _ensure_marp_header(md: str, title: str) -> str:
    header = (
        "---\n"
        "marp: true\n"
        f"paginate: {MARP_PAGINATE}\n"
        f"theme: {MARP_THEME}\n"
        f"title: {title}\n"
        "---\n\n"
    )
    # æ—¢å­˜ã®front-matterã¯å‰¥ãŒã—ã¦å…ˆé ­ã«å†ä»˜ä¸ï¼ˆå®‰å…¨ç­–ï¼‰
    body = re.sub(r"^---[\s\S]*?---\s*", "", md.strip(), count=1, flags=re.DOTALL)
    return header + (body + ("\n" if not body.endswith("\n") else ""))

# ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å£Šã•ãšã« H2 ã®å‰ã¸åŒºåˆ‡ã‚Šã‚’å…¥ã‚Œã‚‹
def _insert_separators(md: str) -> str:
    """
    ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å£Šã•ãšã€H2(## )ã®ç›´å‰ã«1ã¤ã ã‘ '---' ã‚’å…¥ã‚Œã‚‹ã€‚
    """
    out = []
    in_code = False
    fence = None
    prev = ""

    def need_sep(prev_line: str) -> bool:
        pl = prev_line.strip()
        # ç›´å‰ãŒæ—¢ã«åŒºåˆ‡ã‚Šãªã‚‰ä¸è¦
        return pl != "---"

    for line in md.splitlines():
        if line.startswith("```") or line.startswith("~~~"):
            if not in_code:
                in_code, fence = True, line[:3]
            else:
                if fence and line.startswith(fence):
                    in_code, fence = False, None
            out.append(line)
            prev = line
            continue

        if not in_code and line.startswith("## "):
            if need_sep(prev):
                out.append("---")
            out.append(line)
        else:
            out.append(line)
        prev = line

    return "\n".join(out).strip() + "\n"

def _dedupe_separators(md: str) -> str:
    """
    é€£ç¶šã™ã‚‹åŒºåˆ‡ã‚Šï¼ˆ---, ç©ºè¡Œ, --- ...ï¼‰ã‚’1å€‹ã«åœ§ç¸®ã€‚
    """
    # --- ã®é€£ç¶šã‚„ã€--- ã®é–“ã®ç©ºè¡Œã‚’æ½°ã™
    md = re.sub(r"(?:\n*\s*---\s*\n+){2,}", "\n---\n", md, flags=re.MULTILINE)
    # å…ˆé ­ã®ä½™åˆ†ãª --- ã‚’1å€‹ã«
    md = re.sub(r"^(?:\s*---\s*\n)+", "---\n", md)
    return md

def _strip_whole_code_fence(md: str) -> str:
    t = md.strip()
    if t.startswith("```"):
        t = re.sub(r"^```[a-zA-Z0-9_-]*\s*\n?", "", t, flags=re.DOTALL)
        t = re.sub(r"\n?```$", "", t.strip(), flags=re.DOTALL)
    return t

def _clean_title(raw: str) -> str:
    """
    LLMãŒã€ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¿ã‚¤ãƒˆãƒ«â€¦ã€ãªã©å‰ç½®ãã‚„å¼•ç”¨è¨˜å·ã‚’æ··ãœã¦ã‚‚
    1è¡Œã®ç´ ã®ã‚¿ã‚¤ãƒˆãƒ«ã ã‘ã«ã™ã‚‹ã€‚
    """
    t = (raw or "").strip()
    # 1è¡Œç›®ã ã‘æ¡ç”¨
    t = t.splitlines()[0]
    # æ—¥æœ¬èªå¼•ç”¨ã‚„è‹±èªå¼•ç”¨ã‚’é™¤å»
    t = t.strip("ã€Œã€ã€ã€\"' ã€€:ï¼š")
    # å…¸å‹çš„ãªå‰ç½®ãã‚’é™¤å»
    t = re.sub(r"^(ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¿ã‚¤ãƒˆãƒ«.*|title:?|suggested:?|æ¡ˆ:?)[\sï¼š:]*", "", t, flags=re.IGNORECASE)
    return t or "AIæœ€æ–°æƒ…å ±"

# JSTã®ç¾åœ¨æ—¥æ™‚ãƒ„ãƒ¼ãƒ«
JST = ZoneInfo("Asia/Tokyo")

def now_jst():
    return datetime.now(JST)

def today_iso(fmt: str = "%Y-%m-%d") -> str:
    return now_jst().strftime(fmt)

def month_ja() -> str:
    dt = now_jst()
    # Windowsã§ã‚‚å‹•ãã‚ˆã†ã« %-m ã‚’ä½¿ã‚ãšã€0åŸ‹ã‚ã‚‚ã—ãªã„
    return f"{dt.year}å¹´{dt.month}æœˆ"

def month_en() -> str:
    months = ["January","February","March","April","May","June",
              "July","August","September","October","November","December"]
    dt = now_jst()
    return f"{months[dt.month-1]} {dt.year}"

@tool("get_today_jst", return_direct=True)
def get_today_jst(fmt: str = "%Y-%m-%d") -> str:
    """JSTã§ä»Šæ—¥ã®æ—¥ä»˜ã‚’è¿”ã™ï¼ˆä¾‹: %Y-%m-%d, %Yå¹´%mæœˆ ãªã©ï¼‰"""
    return datetime.now(JST).strftime(fmt)

def _clean_title(raw: str) -> str:
    t = (raw or "").strip().splitlines()[0]
    t = t.strip("ã€Œã€ã€ã€\"' ã€€:ï¼š")
    t = re.sub(r"^(ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¿ã‚¤ãƒˆãƒ«.*|title:?|suggested:?|æ¡ˆ:?)[\sï¼š:]*", "", t, flags=re.IGNORECASE)
    return t or "[æœ¬æ—¥ã®æ—¥ä»˜] AIæœ€æ–°æƒ…å ±ã¾ã¨ã‚"

def _strip_whole_code_fence(md: str) -> str:
    t = md.strip()
    if t.startswith("```"):
        t = re.sub(r"^```[a-zA-Z0-9_-]*\s*\n?", "", t, flags=re.DOTALL)
        t = re.sub(r"\n?```$", "", t.strip(), flags=re.DOTALL)
    return t

def _remove_presenter_lines(md: str) -> str:
    """ã‚¿ã‚¤ãƒˆãƒ«ã‚¹ãƒ©ã‚¤ãƒ‰ï¼ˆå…ˆé ­ï½æœ€åˆã®'---'ã¾ã§ï¼‰ã‹ã‚‰ç™ºè¡¨è€…è¡Œã‚’é™¤å»"""
    parts = md.split("\n---\n", 1)
    head = parts[0]
    head = re.sub(r"^\s*(ç™ºè¡¨è€…|Presenter|Speaker)\s*[:ï¼š].*$", "", head, flags=re.MULTILINE)
    head = re.sub(r"\n{3,}", "\n\n", head).strip() + "\n"
    return head + ("\n---\n" + parts[1] if len(parts) == 2 else "")



# -------------------
# Tavily æ¤œç´¢
# -------------------
def tavily_search(
    query: str,
    max_results: int = 8,
    include_domains: Optional[List[str]] = None,
    time_range: str = "month",   # "day" | "week" | "month" | "year"
) -> Dict:
    endpoint = "https://api.tavily.com/search"
    payload: Dict[str, Any] = {
        "api_key": TAVILY_API_KEY,
        "query": query,
        "search_depth": "advanced",
        "include_answer": True,
        "max_results": max_results,
        "time_range": time_range,       # â˜… ç›´è¿‘ã®æƒ…å ±ã«å¯„ã›ã‚‹
    }
    if include_domains:
        payload["include_domains"] = include_domains  # â˜… å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³ã«é™å®š
    r = requests.post(endpoint, json=payload, timeout=60)
    r.raise_for_status()
    return r.json()

def tavily_collect_context(
    queries: List[Union[str, Dict[str, Any]]],
    max_per_query: int = 6,
    default_time_range: str = "month",
) -> Dict[str, List[Dict[str, str]]]:
    """
    queries ã¯ä»¥ä¸‹ã®2å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆ:
      - "plain text"
      - {"q": "...", "include_domains": ["example.com", ...], "time_range": "week"}
    """
    seen = set()
    out: Dict[str, List[Dict[str, str]]] = {}
    for q in queries:
        if isinstance(q, dict):
            qtext = q.get("q", "")
            inc = q.get("include_domains")
            tr  = q.get("time_range", default_time_range)
        else:
            qtext = q
            inc   = None
            tr    = default_time_range

        if not qtext:
            continue

        data = tavily_search(qtext, max_per_query, include_domains=inc, time_range=tr)
        items = []
        for r in data.get("results", []):
            url = r.get("url")
            if not url or url in seen:
                continue
            seen.add(url)
            items.append({
                "title": (r.get("title") or "")[:160],
                "url": url,
                "content": ((r.get("content") or "").replace("\n", " "))[:600],
            })
        out[qtext] = items
    return out

def context_to_bullets(ctx: Dict[str, List[Dict[str, str]]]) -> str:
    # LLMã«æ¸¡ã—ã‚„ã™ã„ã€å‡ºå…¸ä»˜ãã®çŸ­æ–‡ç®‡æ¡æ›¸ãã«ã™ã‚‹
    bullets = []
    for q, items in ctx.items():
        bullets.append(f"### Query: {q}")
        for it in items:
            title = it["title"]
            url = it["url"]
            content = it["content"].replace("\n", " ")
            bullets.append(f"- {title} â€” {content} [source]({url})")
        bullets.append("")  # ç©ºè¡Œ
    return "\n".join(bullets)

# -------------------
# State
# -------------------
class State(TypedDict):
    topic: str
    outline: List[str]
    toc: List[str]
    slide_md: str           # ç”Ÿæˆã•ã‚ŒãŸ Marp ã‚¹ãƒ©ã‚¤ãƒ‰ Markdown
    score: float
    subscores: Dict[str, float]
    reasons: Dict[str, str]
    suggestions: List[str]
    risk_flags: List[str]
    passed: bool
    feedback: str
    title: str
    slide_path: str
    attempts: int
    error: str
    log: List[str]
    # è¿½åŠ 
    context_md: str            # Tavilyã‹ã‚‰ã®è¦ç´„ï¼ˆç®‡æ¡æ›¸ãï¼‰
    sources: Dict[str, List[Dict[str, str]]]  # ç”Ÿã‚½ãƒ¼ã‚¹

# =======================
# Node 0: Tavily æƒ…å ±åé›†ï¼ˆç›´è¿‘2ãƒ¶æœˆ & å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰
# =======================
@traceable(name="0_tavily_collect")
def collect_info(state: State) -> Dict:
    topic = state.get("topic") or "AIæœ€æ–°æƒ…å ±ã¾ã¨ã‚"

    # JSTç¾åœ¨ã¨ æœˆè‹±èªè¡¨è¨˜ï¼ˆä¾‹: "September 2025"ï¼‰
    def month_en_for(dt: datetime) -> str:
        months = ["January","February","March","April","May","June",
                  "July","August","September","October","November","December"]
        return f"{months[dt.month-1]} {dt.year}"

    now = now_jst()
    # å…ˆæœˆã¯ã€Œä»Šæœˆ1æ—¥ã®å‰æ—¥ã€
    prev_month_dt = (now.replace(day=1) - timedelta(days=1))
    month_labels = [month_en_for(now), month_en_for(prev_month_dt)]  # ç›´è¿‘2ãƒ¶æœˆ

    # ãƒ™ãƒ³ãƒ€æ¯ã®å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³
    vendors = [
        (["azure.microsoft.com","news.microsoft.com","learn.microsoft.com"],
         ["Microsoft AI updates", "Azure OpenAI updates"]),
        (["openai.com"], ["OpenAI announcements","OpenAI updates"]),
        (["blog.google","ai.googleblog.com","research.google"], ["Google AI updates", "Gemini updates"]),
        (["aws.amazon.com"], ["AWS Bedrock updates","Amazon AI updates"]),
        (["ai.meta.com"], ["Meta AI updates", "Llama updates"]),
        (["anthropic.com"], ["Anthropic Claude updates","Claude announcements"]),
    ]

    # â˜… ç›´è¿‘2ãƒ¶æœˆ Ã— å„ç¤¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹æˆ
    queries: List[Dict[str, Any]] = []
    for m in month_labels:
        for domains, patterns in vendors:
            for p in patterns:
                queries.append({"q": f"{p} {m}", "include_domains": domains, "time_range": "month"})

    try:
        sources = tavily_collect_context(queries, max_per_query=6, default_time_range="month")
        context_md = context_to_bullets(sources)
        return {
            "sources": sources,
            "context_md": context_md,
            "log": _log(state, f"[tavily] months={month_labels} queries={len(queries)}")
        }
    except Exception as e:
        return {"error": f"tavily_error: {e}", "log": _log(state, f"[tavily] EXCEPTION {e}")}
# -------------------
# Node 1: ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³
# -------------------
@traceable(name="1_outline")
def make_outline(state: State) -> Dict:
    topic = state.get("topic") or "AIæœ€æ–°æƒ…å ±"
    ctx = state.get("context_md") or ""
    prompt = [
        ("system", "ã‚ãªãŸã¯Microsoftã®Solution Engineerã§ã™ã€‚ã“ã‚Œã‹ã‚‰Marpã‚¹ãƒ©ã‚¤ãƒ‰ã§AIæœ€æ–°æƒ…å ±ã‚’ç™ºè¡¨ã—ã¾ã™ã€‚"),
        ("user",
         "ä»¥ä¸‹ã®â€œæœ€æ–°æƒ…å ±ã‚µãƒãƒªï¼ˆå‡ºå…¸ä»˜ãï¼‰â€ã‚’å‚è€ƒã«ã€ç™ºè¡¨ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’å„ç¤¾5å€‹ã€"
         "çŸ­ã„ç®‡æ¡æ›¸ãã§ã€‚URLã‚‚å«ã‚ã¦ãã ã•ã„ã€‚\n\n"
         f"[æœ€æ–°æƒ…å ±ã‚µãƒãƒª]\n{ctx}\n\n[ãƒˆãƒ”ãƒƒã‚¯]\n{topic}")
    ]
    try:
        msg = llm.invoke(prompt)
        bullets = _strip_bullets(msg.content.splitlines())[:5] or [msg.content.strip()]
        return {"outline": bullets, "log": _log(state, f"[outline] {bullets}")}
    except Exception as e:
        return {"error": f"outline_error: {e}", "log": _log(state, f"[outline] EXCEPTION {e}")}

# -------------------
# Node 2: ç›®æ¬¡
# -------------------
@traceable(name="2_make_toc")
def make_toc(state: State) -> Dict:
    outline = state.get("outline") or []
    outline = state.get("outline") or []
    prompt = [
        ("system", "ã‚ãªãŸã¯Microsoftã®Solution Engineerã§ã™ã€‚Marpã‚¹ãƒ©ã‚¤ãƒ‰ã®æ§‹æˆï¼ˆç›®æ¬¡ï¼‰ã‚’ä½œã‚Šã¾ã™ã€‚"),
        ("user",
         "ä»¥ä¸‹ã®ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‹ã‚‰ã€5ã€œ8å€‹ã®ç« ç«‹ã¦ï¼ˆé…åˆ—ï¼‰ã‚’ JSON ã® {\"toc\": [ ... ]} å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚\n\n"
         "ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³:\n- " + "\n- ".join(outline))
    ]
    try:
        msg = llm.invoke(prompt)
        try:
            data = json.loads(_find_json(msg.content) or msg.content)
            toc = [s.strip() for s in data.get("toc", []) if s.strip()]
        except Exception:
            toc = _strip_bullets(msg.content.splitlines())
        toc = toc[:8] or ["ã¯ã˜ã‚ã«", "èƒŒæ™¯", "å®Ÿè£…æ‰‹é †", "è©•ä¾¡ã¨æ”¹å–„", "å…¬é–‹ãƒ»é‹ç”¨", "ã¾ã¨ã‚"]
        return {"toc": toc, "error": "", "log": _log(state, f"[toc] {toc}")}
    except Exception as e:
        return {"error": f"toc_error: {e}", "log": _log(state, f"[toc] EXCEPTION {e}")}

# -------------------
# Node 3: ã‚¹ãƒ©ã‚¤ãƒ‰æœ¬æ–‡ï¼ˆMarpï¼‰
# -------------------
@traceable(name="3_write_slides")
def write_slides(state: State) -> Dict:
    ctx = state.get("context_md") or ""   # â˜… ã“ã“ãŒé‡è¦
    sources = state.get("sources") or {}

    # å‚è€ƒãƒªãƒ³ã‚¯ï¼ˆæœ€å¤§æ§ãˆã‚ï¼‰
    refs = []
    for q, items in sources.items():
        for it in items[:2]:
            refs.append(f"- **{it['title']}** â€” {it['url']}")
    refs_md = "\n".join(refs)

    # â–¼ ã‚¿ã‚¤ãƒˆãƒ«ã¯å½“æœˆã§è‡ªå‹•å›ºå®šï¼ˆLLMã«ä»»ã›ãªã„ï¼‰
    ja_title = f"{month_ja()}_AIæœ€æ–°æƒ…å ±ã‚»ãƒƒã‚·ãƒ§ãƒ³"

    prompt = [
        ("system",
         "ã‚ãªãŸã¯Microsoftã®Solution Engineerã§ã€Marpå½¢å¼ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½œã‚Šã¾ã™ã€‚"
         "å‡ºåŠ›ã¯ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§å›²ã¾ãšã€ã‚¹ãƒ©ã‚¤ãƒ‰åŒºåˆ‡ã‚Šï¼ˆ---ï¼‰ã¯å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚"
         "å„ã‚¹ãƒ©ã‚¤ãƒ‰ã¯å¿…ãš H2 è¦‹å‡ºã—ï¼ˆ## ï¼‰ã§é–‹å§‹ã€‚ã‚¿ã‚¤ãƒˆãƒ«ã‚¹ãƒ©ã‚¤ãƒ‰ã«ç™ºè¡¨è€…åã¯æ›¸ã‹ãªã„ã§ãã ã•ã„ã€‚"
         "é‡è¦: ä»¥ä¸‹ã®â€œæœ€æ–°æƒ…å ±ã‚µãƒãƒªâ€ã®ç¯„å›²å†…ã®äº‹å®Ÿã®ã¿ã«åŸºã¥ã„ã¦ä½œæˆã—ã€ã‚µãƒãƒªã«ç„¡ã„æƒ…å ±ã¯æ›¸ã‹ãªã„ã§ãã ã•ã„ã€‚"),
        ("user",
         "æœ€æ–°æƒ…å ±ã‚µãƒãƒªï¼ˆå‡ºå…¸ä»˜ãï¼‰:\n"
         f"{ctx}\n\n"
         "è¦ä»¶:\n"
         f"- ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè¡¨ç´™ã®å¤§è¦‹å‡ºã—ï¼‰: {ja_title}\n"
         "- 1ãƒšãƒ¼ã‚¸ç›®ã¯ # è¦‹å‡ºã—ã¨çŸ­ã„ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ï¼ˆç™ºè¡¨è€…åã¯æ›¸ã‹ãªã„ï¼‰\n"
         "- 2ãƒšãƒ¼ã‚¸ç›®ã¯ Agendaï¼ˆç« ç«‹ã¦ã‚’åˆ—æŒ™ï¼‰\n"
         "- ä»¥é™ã¯å„ç¤¾ã”ã¨ã®AIæœ€æ–°æƒ…å ±ã‚’ç°¡æ½”ã«ã€‚å„é …ç›®ã«URLã‚’å«ã‚ã‚‹\n"
         "- å„ç« ã¯å¿…ãš H2ï¼ˆ## ï¼‰ã§å§‹ã‚ã‚‹")
    ]

    try:
        msg = llm.invoke(prompt)
        slide_md = msg.content.strip()

        # 1) å…¨ä½“ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã‚’å‰¥ãŒã™
        slide_md = _strip_whole_code_fence(slide_md)
        # 2) H2ã®ç›´å‰ã«ã ã‘ --- ã‚’è‡ªå‹•æŒ¿å…¥
        slide_md = _insert_separators(slide_md)
        # 3) é€£ç¶šã™ã‚‹ --- ã‚’1ã¤ã«åœ§ç¸®
        slide_md = _dedupe_separators(slide_md)
        # 4) front-matter ã‚’å…ˆé ­ã«ä»˜ä¸ï¼ˆtitle ã¯â€œã‚¿ã‚¤ãƒˆãƒ«ã ã‘â€ï¼‰
        slide_md = _ensure_marp_header(slide_md, _clean_title(ja_title))
        # 5) è¡¨ç´™ã‹ã‚‰â€œç™ºè¡¨è€…: â€¦â€ãªã©ã‚’é™¤å»
        slide_md = _remove_presenter_lines(slide_md)

        return {"slide_md": slide_md, "title": ja_title,
                "error": "", "log": _log(state, f"[slides] generated ({len(slide_md)} chars)")}
    except Exception as e:
        return {"error": f"slides_error: {e}", "log": _log(state, f"[slides] EXCEPTION {e}")}

# -------------------
# Node 4: è©•ä¾¡ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰å‰æï¼‰
# -------------------
MAX_ATTEMPTS = 3

@traceable(name="4_evaluate_slides")
def evaluate_slides(state: State) -> Dict:
    if state.get("error"):
        return {}
    slide_md = state.get("slide_md") or ""
    toc = state.get("toc") or []
    topic = state.get("topic") or ""
    eval_guide = (
        "è©•ä¾¡è¦³ç‚¹ã¨é‡ã¿:\n"
        "- structure(0.20): ã‚¹ãƒ©ã‚¤ãƒ‰ã®æµã‚Œã€ç« ç«‹ã¦ã€1ã‚¹ãƒ©ã‚¤ãƒ‰1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n"
        "- practicality(0.25): å®Ÿå‹™ã«ä½¿ãˆã‚‹å…·ä½“æ€§ï¼ˆæ‰‹é †ã€ã‚³ãƒ¼ãƒ‰ä¾‹ã€æ³¨æ„ç‚¹ï¼‰\n"
        "- accuracy(0.25): äº‹å®Ÿãƒ»APIä»•æ§˜ãƒ»ç”¨èªã®æ­£ç¢ºã•\n"
        "- readability(0.15): ç°¡æ½”æ˜ç­ã€è¦–èªæ€§ï¼ˆç®‡æ¡æ›¸ãã®ç²’åº¦ï¼‰\n"
        "- conciseness(0.15): å†—é•·æ€§ã®å°‘ãªã•\n"
        "åˆæ ¼: score >= 8.0\n"
    )

    prompt = [
        ("system",
         "ã‚ãªãŸã¯Microsoftã®Cloud Solution Architectã§ã™ã€‚ä»¥ä¸‹ã®Marpã‚¹ãƒ©ã‚¤ãƒ‰Markdownã‚’ã€"
         "æŒ‡å®šã®è¦³ç‚¹ãƒ»é‡ã¿ã§å³å¯†ã«æ¡ç‚¹ã—ã¾ã™ã€‚å‡ºåŠ›ã¯JSONã®ã¿ã€‚"),
        ("user",
         f"Topic: {topic}\nTOC: {json.dumps(toc, ensure_ascii=False)}\n\n"
         "Slides (Marp Markdown):\n<<<SLIDES\n" + slide_md + "\nSLIDES\n\n"
         "Evaluation Guide:\n<<<EVAL\n" + eval_guide + "\nEVAL\n\n"
         "Return strictly this JSON schema:\n"
         "{\n"
         "  \"score\": number,\n"
         "  \"subscores\": {\"structure\": number, \"practicality\": number, \"accuracy\": number, \"readability\": number, \"conciseness\": number},\n"
         "  \"reasons\": {\"structure\": string, \"practicality\": string, \"accuracy\": string, \"readability\": string, \"conciseness\": string},\n"
         "  \"suggestions\": [string],\n"
         "  \"risk_flags\": [string],\n"
         "  \"pass\": boolean,\n"
         "  \"feedback\": string\n"
         "}"
    )]
    try:
        msg = llm.invoke(prompt)
        raw = msg.content or ""
        js = _find_json(raw) or raw
        data = json.loads(js)

        score = float(data.get("score", 0.0))
        subscores = data.get("subscores") or {}
        reasons = data.get("reasons") or {}
        suggestions = data.get("suggestions") or []
        risk_flags = data.get("risk_flags") or []
        passed = bool(data.get("pass", score >= 8.0))
        feedback = str(data.get("feedback", "")).strip()
        attempts = (state.get("attempts") or 0) + 1

        return {
            "score": score,
            "subscores": subscores,
            "reasons": reasons,
            "suggestions": suggestions,
            "risk_flags": risk_flags,
            "passed": passed,
            "feedback": feedback,
            "attempts": attempts,
            "log": _log(state, f"[evaluate] score={score:.2f} pass={passed} attempts={attempts}")
        }
    except Exception as e:
        return {"error": f"eval_error: {e}", "log": _log(state, f"[evaluate] EXCEPTION {e}")}

def route_after_eval(state: State) -> str:
    if (state.get("attempts") or 0) >= MAX_ATTEMPTS:
        return "ok"
    return "ok" if state.get("passed") else "retry"

# -------------------
# Node 5: ä¿å­˜ & Marpãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
# -------------------
@traceable(name="5_save_and_render")
def save_and_render(state: State) -> Dict:
    if state.get("error"):
        return {}
    slide_md = state.get("slide_md") or ""
    title = state.get("title") or "AIã‚¹ãƒ©ã‚¤ãƒ‰"

    # ãƒ•ã‚¡ã‚¤ãƒ«å
    slug_prompt = [
        ("system", "You create concise English slugs for filenames."),
        ("user",
         "Convert the following Japanese title into a short English filename base (<=6 words). "
         "Only letters and spaces; no punctuation or numbers.\n\n"
         f"Title: {title}")
    ]
    emsg = llm.invoke(slug_prompt)
    file_stem = _slugify_en(emsg.content.strip()) or _slugify_en(title)

    slides_dir = Path("slides")
    slides_dir.mkdir(parents=True, exist_ok=True)
    slide_md_path = slides_dir / f"{file_stem}_slides.md"
    slide_md_path.write_text(slide_md, encoding="utf-8")

    # marp-cli ã§å‡ºåŠ›
    marp = shutil.which("marp")
    out_path = str(slide_md_path)
    if marp and SLIDE_FORMAT in {"pdf", "png", "html"}:
        ext = SLIDE_FORMAT
        out_file = slides_dir / f"{file_stem}.{ext}"
        try:
            subprocess.run(
                [marp, str(slide_md_path), f"--{ext}", "-o", str(out_file)],
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )
            out_path = str(out_file)
            log_msg = f"[marp] generated {ext} -> {out_file}"
        except subprocess.CalledProcessError as e:
            log_msg = f"[marp] marp-cli failed: {e}"
    else:
        if not marp and SLIDE_FORMAT:
            log_msg = "[marp] marp-cli not found â€“ skipped rendering (left .md)."
        else:
            log_msg = "[marp] rendering skipped (SLIDE_FORMAT not set)."

    return {"slide_path": out_path, "log": _log(state, log_msg)}

# -------------------
# ã‚°ãƒ©ãƒ•æ§‹ç¯‰
# -------------------
graph_builder = StateGraph(State)
graph_builder.add_node("collect_info", collect_info)
graph_builder.add_node("make_outline", make_outline)
graph_builder.add_node("make_toc", make_toc)
graph_builder.add_node("write_slides", write_slides)
graph_builder.add_node("evaluate_slides", evaluate_slides)
graph_builder.add_node("save_and_render", save_and_render)

graph_builder.add_edge(START, "collect_info")
graph_builder.add_edge("collect_info", "make_outline")
graph_builder.add_edge("make_outline", "make_toc")
graph_builder.add_edge("make_toc", "write_slides")
graph_builder.add_edge("write_slides", "evaluate_slides")

graph_builder.add_conditional_edges(
    "evaluate_slides",
    route_after_eval,
    {"retry": "make_toc", "ok": "save_and_render"},
)

graph_builder.add_edge("save_and_render", END)

graph = graph_builder.compile()

# -------------------
# å®Ÿè¡Œ
# -------------------
if __name__ == "__main__":
    print("LangSmith Tracing:", os.getenv("LANGCHAIN_TRACING_V2"),
          "| Project:", os.getenv("LANGCHAIN_PROJECT"))
    init: State = {
        "topic": "LangGraph Ã— LangSmith Ã— Azure OpenAI Ã— Tavilyã§ä½œã‚‹ï¼šæœ€æ–°AIå‹•å‘ã‚¹ãƒ©ã‚¤ãƒ‰",
        "outline": [], "toc": [], "slide_md": "",
        "score": 0.0,
        "subscores": {}, "reasons": {},
        "suggestions": [], "risk_flags": [],
        "passed": False, "feedback": "",
        "title": "", "slide_path": "",
        "attempts": 0, "error": "", "log": [],
        "context_md": "", "sources": {}
    }
    config: RunnableConfig = {
        "run_name": "tavily-marp-agent",
        "tags": ["marp", "langgraph", "langsmith", "azure-openai", "tavily"],
        "metadata": {"env": "dev", "date": datetime.utcnow().isoformat()},
        "recursion_limit": 60,
    }
    out = graph.invoke(init, config=config)

    print("\n=== RESULT ===")
    if out.get("error"):
        print("ERROR:", out["error"])
    else:
        print("Title    :", out.get("title"))
        print("Slide    :", out.get("slide_path"))
        print("Score    :", out.get("score"))
        print("Passed   :", out.get("passed"))
    print("\n-- LOG --")
    for line in out.get("log", []):
        print(line)
````

ã‚³ãƒ¼ãƒ‰ã®å®Ÿè£…ã¯ã“ã‚Œã§å®Œäº†ã§ã™ã€‚
ã§ã¯ã€å®Ÿè¡Œã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼

## å®Ÿè¡Œ

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€LangSmith ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãŒé–‹ãã¾ã™ã€‚

```bash
langgraph dev
```

![](https://storage.googleapis.com/zenn-user-upload/2b4949af5e6a-20250906.png)

ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãŒé–‹ã„ãŸã‚‰ã€ç”»é¢ä¸­å¤®ä¸‹éƒ¨ã® Submit ãƒœã‚¿ãƒ³ã‚’æ•™ãˆã¦å®Ÿè¡Œã—ã¾ã™ã€‚
![](https://storage.googleapis.com/zenn-user-upload/2bd8835b0164-20250906.png)

å®Ÿè¡ŒãŒå®Œäº†ã™ã‚‹ã¨ã€slides ãƒ•ã‚©ãƒ«ãƒ€ã« PDF ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚
![](https://storage.googleapis.com/zenn-user-upload/1d5739ee32e4-20250906.png)

ã„ã„æ„Ÿã˜ã«å„ç¤¾ã® Update ãŒã¾ã¨ã¾ã£ã¦ã„ã¾ã™ã­ï¼
ã“ã‚Œã§ã‚¹ãƒ©ã‚¤ãƒ‰è³‡æ–™ã®å®Œæˆã§ã™ã€‚

å®Ÿè£…ãŠç–²ã‚Œæ§˜ã§ã—ãŸã€‚

# ã¾ã¨ã‚

ä»Šå›ã¯ LangGraph ã¨ LangSmith ã‚’ä½¿ã£ã¦ã€AI æœ€æ–°æƒ…å ±ã‚’åé›†ã—ã€Marp ã§ã‚¹ãƒ©ã‚¤ãƒ‰è³‡æ–™ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚
LangGraph ã®çŠ¶æ…‹é·ç§»ã¨ LangSmith ã®ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°æ©Ÿèƒ½ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚‚ AIAgent ãŒã©ã®ã‚ˆã†ãªå‹•ãã‚’ã—ã¦ã„ã‚‹ã‹è¦‹ãªãŒã‚‰å®Ÿè£…ã™ã‚‹ã“ã¨ãŒå‡ºæ¥ã‚‹ã®ã§ã€å€‹äººçš„ã«ã¯ã‹ãªã‚ŠãŠã™ã™ã‚ã®æ©Ÿèƒ½ã§ã—ãŸã€‚

æ˜¯éã¿ãªã•ã‚“ã‚‚è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚

ãã‚Œã§ã¯ ğŸ–ï¸

# ç­†è€…æƒ…å ±

https://x.com/fe_js_engineer
https://www.linkedin.com/in/satyus/

# å‚è€ƒãƒªãƒ³ã‚¯

https://www.langchain.com/
https://www.langchain.com/langgraph
https://www.langchain.com/langsmith
